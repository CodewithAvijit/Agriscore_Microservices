{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7fefa55",
   "metadata": {},
   "source": [
    "PIPELINE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a15c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import optuna\n",
    "import joblib\n",
    "\n",
    "data = pd.read_csv(r\"C:\\Users\\Avijit\\Desktop\\AgriAssure\\AGRIYIELDPRO\\PROCESSED_DATASET\\yield5.csv\")\n",
    "\n",
    "\n",
    "# --- Data Preparation ---\n",
    "# Separate features (x) and target (y)\n",
    "x = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1:]\n",
    "y1 = np.reshape(y, newshape=(-1))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y1, train_size=0.8, random_state=32)\n",
    "\n",
    "# --- Define the Hyperparameter Optimization Objective Function ---\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    This function defines the search space for Optuna.\n",
    "    Optuna will try different combinations of these hyperparameters\n",
    "    to find the best model performance.\n",
    "    \"\"\"\n",
    "    # Suggest a range of values for each hyperparameter\n",
    "    param = {\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
    "        'max_iter': trial.suggest_int('max_iter', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 5, 20),\n",
    "        'l2_regularization': trial.suggest_loguniform('l2_regularization', 1e-3, 10.0),\n",
    "    }\n",
    "\n",
    "    # Create the pipeline with the suggested parameters\n",
    "    # A StandardScaler is included as a good practice, even though\n",
    "    # tree-based models are not sensitive to feature scaling.\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', HistGradientBoostingRegressor(**param))\n",
    "    ])\n",
    "\n",
    "    # Use K-Fold Cross-Validation to get a robust score for the trial\n",
    "    cv_folds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    score = cross_val_score(pipeline, xtrain, ytrain, cv=cv_folds, scoring='r2', n_jobs=-1)\n",
    "\n",
    "    # Optuna minimizes the objective function, so we return the negative R2 score\n",
    "    return np.mean(score) * -1\n",
    "\n",
    "# --- Run the Optuna Study ---\n",
    "print(\"Starting hyperparameter optimization with Optuna...\")\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=True)\n",
    "print(\"Optimization complete.\")\n",
    "\n",
    "# --- Get the Best Hyperparameters ---\n",
    "best_params = study.best_params\n",
    "best_score = -study.best_value\n",
    "print(\"\\n--- Best Results ---\")\n",
    "print(f\"Best R-squared score found: {best_score:.4f}\")\n",
    "print(\"Best hyperparameters found:\")\n",
    "for key, value in best_params.items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "# --- Train the Final Pipeline with the Best Parameters ---\n",
    "print(\"\\nTraining the final model with the best parameters...\")\n",
    "final_pipeline = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', HistGradientBoostingRegressor(**best_params))\n",
    "])\n",
    "final_pipeline.fit(xtrain, ytrain)\n",
    "print(\"Final model training complete.\")\n",
    "\n",
    "# --- Evaluate the Final Model on the Test Set ---\n",
    "train_score = final_pipeline.score(xtrain, ytrain)\n",
    "test_score = final_pipeline.score(xtest, ytest)\n",
    "print(f\"Final R-squared on training data: {train_score:.4f}\")\n",
    "print(f\"Final R-squared on testing data: {test_score:.4f}\")\n",
    "\n",
    "# --- Save the Entire Optimized Pipeline ---\n",
    "# Saving the entire pipeline ensures both the scaler and the regressor are saved together.\n",
    "joblib.dump(final_pipeline, r\"C:\\Users\\Avijit\\Desktop\\AgriAssure\\AGRIYIELDPRO\\MODEL\\histgradientboostingV3.pkl\")\n",
    "print(\"\\nOptimized pipeline saved to optimized_histgradboosting_pipeline.pkl\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
